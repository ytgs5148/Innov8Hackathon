{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INNOV8: The Space Saga\n",
    "This is the solution to the **Part 1: Decoding and Classifying Alien Commu-\n",
    "nications** of the INNOV8: The Space Saga challenge. The solution is implemented in Python using TensorFlow and Scikit-learn libraries.\n",
    "\n",
    "## 1. Importing Libraries\n",
    "We first import essential libraries such as Pandas for data handling, Numpy for numerical operations, TensorFlow for building the neural network, and Scikit-learn utilities for feature extraction and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Pre-Processing Data\n",
    "We load the training and test datasets, pre-process the categorical column `tail` by converting it into binary values, and apply vectorization to the text data (`message`). Additionally, numeric columns (`fingers` and `tail`) are scaled to ensure all features are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing alien data and submission data\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "submission = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# Converting the tail column into binary values\n",
    "data['tail'] = data['tail'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "submission['tail'] = submission['tail'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "X_text = vectoriser.fit_transform(data['message']).toarray()\n",
    "X_submission_text = vectoriser.transform(submission['message']).toarray()\n",
    "X_numeric_scaled = scaler.fit_transform(data[['fingers', 'tail']].values)\n",
    "X_submission_numeric_scaled = scaler.transform(submission[['fingers', 'tail']].values)\n",
    "\n",
    "encoded_data = np.concatenate((X_text, X_numeric_scaled), axis=1)\n",
    "encoded_species = le.fit_transform(data['species'])\n",
    "encoded_submission = np.concatenate((X_submission_text, X_submission_numeric_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Neural Network\n",
    "We define a feedforward neural network with two hidden layers, compile it using the RMSprop optimizer, and train the model on the preprocessed data. Class weights are computed to handle class imbalance, and early stopping is used to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytgsg\\Desktop\\Dev\\Innov8Hackathon\\.conda\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - 550ms/step - accuracy: 0.1000 - loss: 2.6528\n",
      "Epoch 2/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.2660 - loss: 2.5745\n",
      "Epoch 3/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.3540 - loss: 2.5094\n",
      "Epoch 4/45\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.4120 - loss: 2.4525\n",
      "Epoch 5/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.4220 - loss: 2.3868\n",
      "Epoch 6/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.4640 - loss: 2.3080\n",
      "Epoch 7/45\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5060 - loss: 2.2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ytgsg\\Desktop\\Dev\\Innov8Hackathon\\.conda\\lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5360 - loss: 2.1727\n",
      "Epoch 9/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5720 - loss: 2.1083\n",
      "Epoch 10/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5840 - loss: 2.0352\n",
      "Epoch 11/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5680 - loss: 1.9798\n",
      "Epoch 12/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.6440 - loss: 1.9013\n",
      "Epoch 13/45\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.6400 - loss: 1.8437\n",
      "Epoch 14/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.6900 - loss: 1.7706\n",
      "Epoch 15/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.7400 - loss: 1.6907\n",
      "Epoch 16/45\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.7240 - loss: 1.6336\n",
      "Epoch 17/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.7320 - loss: 1.5852\n",
      "Epoch 18/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.7500 - loss: 1.5154\n",
      "Epoch 19/45\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7940 - loss: 1.4395\n",
      "Epoch 20/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.8020 - loss: 1.3705\n",
      "Epoch 21/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8260 - loss: 1.3230\n",
      "Epoch 22/45\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.8580 - loss: 1.2404\n",
      "Epoch 23/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.8540 - loss: 1.1792\n",
      "Epoch 24/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8660 - loss: 1.1021\n",
      "Epoch 25/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8560 - loss: 1.0746\n",
      "Epoch 26/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.8700 - loss: 1.0125\n",
      "Epoch 27/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.8740 - loss: 0.9837\n",
      "Epoch 28/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.8800 - loss: 0.9263\n",
      "Epoch 29/45\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.8940 - loss: 0.8708\n",
      "Epoch 30/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8800 - loss: 0.8548\n",
      "Epoch 31/45\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.8880 - loss: 0.8110\n",
      "Epoch 32/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8940 - loss: 0.7845\n",
      "Epoch 33/45\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.8760 - loss: 0.7675\n",
      "Epoch 34/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.8920 - loss: 0.7530\n",
      "Epoch 35/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.8980 - loss: 0.7356\n",
      "Epoch 36/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.9060 - loss: 0.7048\n",
      "Epoch 37/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.9060 - loss: 0.6889\n",
      "Epoch 38/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.9040 - loss: 0.6729\n",
      "Epoch 39/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.9100 - loss: 0.6570\n",
      "Epoch 40/45\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.9080 - loss: 0.6232\n",
      "Epoch 41/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.9080 - loss: 0.6336\n",
      "Epoch 42/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.9060 - loss: 0.6179\n",
      "Epoch 43/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.9100 - loss: 0.6058\n",
      "Epoch 44/45\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.9060 - loss: 0.5949\n",
      "Epoch 45/45\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.9220 - loss: 0.5780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a66c5e91e0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = encoded_data, encoded_species\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=45, batch_size=4096, callbacks=[early_stopping], verbose=2, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making Predictions\n",
    "Once the model is trained, we use it to make predictions on the test dataset. The predicted species are then decoded using the label encoder and saved into a CSV file for submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(encoded_submission)\n",
    "le.fit(data['species'])\n",
    "predicted_species = le.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "submission['species'] = predicted_species\n",
    "submission[['species']].to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
