{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INNOV8: The Space Saga\n",
    "This is the solution to the **Part 1: Decoding and Classifying Alien Commu-\n",
    "nications** of the INNOV8: The Space Saga challenge. The solution is implemented in Python using TensorFlow and Scikit-learn libraries.\n",
    "\n",
    "## 1. Importing Libraries\n",
    "We first import essential libraries such as Pandas for data handling, Numpy for numerical operations, TensorFlow for building the neural network, and Scikit-learn utilities for feature extraction and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Pre-Processing Data\n",
    "We load the training and test datasets, pre-process the categorical column `tail` by converting it into binary values, and apply vectorization to the text data (`message`). Additionally, numeric columns (`fingers` and `tail`) are scaled to ensure all features are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing alien data and submission data\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "submission = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# Converting the tail column into binary values\n",
    "data['tail'] = data['tail'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "submission['tail'] = submission['tail'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "X_text = vectoriser.fit_transform(data['message']).toarray()\n",
    "X_submission_text = vectoriser.transform(submission['message']).toarray()\n",
    "X_numeric_scaled = scaler.fit_transform(data[['fingers', 'tail']].values)\n",
    "X_submission_numeric_scaled = scaler.transform(submission[['fingers', 'tail']].values)\n",
    "\n",
    "encoded_data = np.concatenate((X_text, X_numeric_scaled), axis=1)\n",
    "encoded_species = le.fit_transform(data['species'])\n",
    "encoded_submission = np.concatenate((X_submission_text, X_submission_numeric_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Neural Network\n",
    "We define a feedforward neural network with two hidden layers, compile it using the RMSprop optimizer, and train the model on the preprocessed data. Class weights are computed to handle class imbalance, and early stopping is used to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = encoded_data, encoded_species\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=45, batch_size=4096, callbacks=[early_stopping], verbose=2, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making Predictions\n",
    "Once the model is trained, we use it to make predictions on the test dataset. The predicted species are then decoded using the label encoder and saved into a CSV file for submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(encoded_submission)\n",
    "le.fit(data['species'])\n",
    "predicted_species = le.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "submission['species'] = predicted_species\n",
    "submission[['species']].to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
